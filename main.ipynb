{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from types import SimpleNamespace\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:08:48\n",
      "-------------------------------------------\n",
      "('neutral', 3)\n",
      "('positive', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:08:58\n",
      "-------------------------------------------\n",
      "('neutral', 3)\n",
      "('positive', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:09:08\n",
      "-------------------------------------------\n",
      "('neutral', 1)\n",
      "('positive', 1)\n",
      "('negative', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:09:18\n",
      "-------------------------------------------\n",
      "('neutral', 3)\n",
      "('negative', 2)\n",
      "('positive', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:09:28\n",
      "-------------------------------------------\n",
      "('neutral', 2)\n",
      "('positive', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:09:38\n",
      "-------------------------------------------\n",
      "('neutral', 6)\n",
      "('positive', 8)\n",
      "('negative', 2)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:09:48\n",
      "-------------------------------------------\n",
      "('neutral', 3)\n",
      "('positive', 6)\n",
      "('negative', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:09:58\n",
      "-------------------------------------------\n",
      "('neutral', 6)\n",
      "('positive', 5)\n",
      "('negative', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:10:08\n",
      "-------------------------------------------\n",
      "('positive', 2)\n",
      "('negative', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:10:18\n",
      "-------------------------------------------\n",
      "('neutral', 4)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:10:28\n",
      "-------------------------------------------\n",
      "('neutral', 6)\n",
      "('positive', 5)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:10:38\n",
      "-------------------------------------------\n",
      "('neutral', 2)\n",
      "('negative', 2)\n",
      "('positive', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:10:48\n",
      "-------------------------------------------\n",
      "('neutral', 4)\n",
      "('positive', 1)\n",
      "('negative', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:10:58\n",
      "-------------------------------------------\n",
      "('positive', 3)\n",
      "('negative', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:11:08\n",
      "-------------------------------------------\n",
      "('neutral', 4)\n",
      "('positive', 7)\n",
      "('negative', 3)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:11:18\n",
      "-------------------------------------------\n",
      "('neutral', 7)\n",
      "('negative', 2)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-04-28 14:11:28\n",
      "-------------------------------------------\n",
      "('neutral', 1)\n",
      "('positive', 3)\n",
      "('negative', 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def update_function(new_values, running_sum):\n",
    "  if running_sum is None:\n",
    "    running_sum = 0\n",
    "  return sum(new_values, running_sum)\n",
    "\n",
    "# text classification\n",
    "def polarity_detection(text):\n",
    "  polarity = TextBlob(text).sentiment.polarity\n",
    "\n",
    "  if polarity < -0.1:\n",
    "    return -1\n",
    "  elif polarity >= -0.1 and polarity <= 0.1:\n",
    "    return 0\n",
    "  elif polarity > 0.1:\n",
    "    return 1\n",
    "\n",
    "def get_sentiment(text):\n",
    "  positive = 0\n",
    "  negative = 0\n",
    "  neutral = 0\n",
    "\n",
    "  sentiment_result = polarity_detection(text)\n",
    "\n",
    "  if sentiment_result == 1:\n",
    "    positive += 1\n",
    "    return (\"positive\", positive)\n",
    "\n",
    "  elif sentiment_result == -1:\n",
    "    negative += 1\n",
    "    return (\"negative\", negative)\n",
    "\n",
    "  elif sentiment_result == 0:\n",
    "    neutral += 1\n",
    "    return (\"neutral\", neutral)\n",
    "  \n",
    "def process_lines(lines, window_length = 2, sliding_interval = 2):\n",
    "    \"\"\"\n",
    "    Function to process \"text\" from tweet object in each window operation\n",
    "    Params:\n",
    "        lines: Spark DStream defined above\n",
    "        window_length: length of window in windowing operation\n",
    "        sliding_interval: sliding interval for the window operation\n",
    "    Return:\n",
    "        result: DStream (RDD) of variance result with \n",
    "                format --> ('positive:', num_positive), ('negative:', num_negative), ('neutral:', num_neutral)\n",
    "                Example:   ('positive:', 1), ('negative:', 3), ('neutral:', 2)\n",
    "    \"\"\"\n",
    "    # tweets = lines.flatMap(lambda line: line[1].split(\"\\n\\n\"))\n",
    "    # objects = tweets.map(lambda tweet: json.loads(tweet, object_hook=lambda d: SimpleNamespace(**d)))\n",
    "\n",
    "    # texts = objects.map(lambda obj: obj.text) # if using OAuth1\n",
    "    texts = lines.map(lambda obj: obj[1]) # if using OAuth1\n",
    "\n",
    "    ### if using OAuth2\n",
    "    # texts = lines.map(lambda obj: obj.data.text) \n",
    "\n",
    "    sentiments = texts.map(get_sentiment) # apply sentiment analysis library here\n",
    "\n",
    "    result = sentiments.reduceByKeyAndWindow(lambda x, y: x + y, lambda x, y: x - y, window_length, sliding_interval)\n",
    "\n",
    "    ### use this if you want to have accumulative sentiments, not windowed sentiments\n",
    "    # accumulative = result.updateStateByKey(update_function) \n",
    "    # return accumulative\n",
    "\n",
    "    return result\n",
    "\n",
    "def prepare_query_value(data):\n",
    "  global positive, negative, neutral\n",
    "\n",
    "  if data[0] == \"positive\":\n",
    "    positive.add(int(data[1]))\n",
    "  elif data[0] == \"negative\":\n",
    "    negative.add(int(data[1]))\n",
    "  elif data[0] == \"neutral\":\n",
    "    neutral.add(int(data[1]))\n",
    "\n",
    "def insert_to_table(rdd):\n",
    "  connection = psycopg2.connect(\n",
    "    user = 'bigdata',\n",
    "    password = 'tweet',\n",
    "    host = 'fata.tech',\n",
    "    port = '5432',\n",
    "    database = 'bigdata'\n",
    "  )\n",
    "  cursor = connection.cursor()\n",
    "\n",
    "  rdd.foreach(lambda data: prepare_query_value(data))\n",
    "\n",
    "  query = \"\"\"INSERT INTO sentiments(positive, negative, neutral) VALUES (%s, %s, %s)\"\"\"\n",
    "  cursor.execute(query, (positive.value, negative.value, neutral.value))\n",
    "\n",
    "  connection.commit()\n",
    "  cursor.close()\n",
    "  connection.close()\n",
    "\n",
    "  positive.add(positive.value * (-1))\n",
    "  negative.add(negative.value * (-1))\n",
    "  neutral.add(neutral.value * (-1))\n",
    "\n",
    "# Environment variables\n",
    "APP_NAME = \"PySpark PostgreSQL - via JDBC\"\n",
    "MASTER = \"local\"\n",
    "\n",
    "KAFKA_TOPIC = \"america\"\n",
    "BOOTSTRAP_SERVER = \"fata.tech:9092\"\n",
    "\n",
    "# Spark configurations\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(APP_NAME) \\\n",
    "    .setMaster(MASTER)\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "ssc = StreamingContext(sc, 1) # stream each one second\n",
    "ssc.checkpoint(\"./checkpoint\")\n",
    "\n",
    "positive = sc.accumulator(0)\n",
    "negative = sc.accumulator(0)\n",
    "neutral = sc.accumulator(0)\n",
    "\n",
    "# Consume Kafka topic\n",
    "lines = KafkaUtils.createDirectStream(ssc, [KAFKA_TOPIC], {\"metadata.broker.list\": BOOTSTRAP_SERVER})\n",
    "\n",
    "# Process lines retrieved from Kafka topic\n",
    "result = process_lines(lines, window_length=10, sliding_interval=10)\n",
    "\n",
    "# Print the result\n",
    "result.pprint()\n",
    "\n",
    "# Insert to table\n",
    "result.foreachRDD(insert_to_table)\n",
    "\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
